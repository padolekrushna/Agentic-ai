# ✅ Step 1: Clean install
!pip install -q langchain duckduckgo-search gradio transformers huggingface_hub

# ✅ Step 2: Imports
import os, gradio as gr
from langchain.agents import Tool, initialize_agent, AgentType
from langchain.llms import HuggingFaceHub
from langchain.tools import DuckDuckGoSearchRun

# ✅ Step 3: Set your Hugging Face token (must include inference permissions)
os.environ["HUGGINGFACEHUB_API_TOKEN"] = "hf_your_token_here"

# ✅ Step 4: Instantiate fast and stable LLM
llm = HuggingFaceHub(
    repo_id="google/flan-t5-small",
    model_kwargs={"temperature": 0.2, "max_new_tokens": 128}
)

# ✅ Step 5: Setup the web search tool (only string input expected)
search_tool = DuckDuckGoSearchRun()

tools = [
    Tool(
        name="WebSearch",
        func=search_tool.run,  # takes a single string
        description="Search the web quickly by giving a search query"
    )
]

# ✅ Step 6: Build agent with only one tool (avoid schema mismatch)
agent = initialize_agent(
    tools=tools,
    llm=llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=False
)

# ✅ Step 7: Gradio interface
def run_agent(query: str) -> str:
    return agent.run(query)

gr.Interface(
    fn=run_agent,
    inputs=gr.Textbox(label="Your Query"),
    outputs=gr.Textbox(label="Agent Answer"),
    title="✅ Simple Agent: Search + LLM",
    description="Only uses DuckDuckGo + FLAN‑T5 to fully avoid input schema errors."
).launch()
