The API status of Grok API and the open source import gradio as gr
import requests
import json
from datetime import datetime
import time
from typing import Dict, Any, Optional
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class APIValidator:
    """Validate API endpoints and keys"""
    
    @staticmethod
    def test_groq_api(token: str) -> bool:
        if not token or token == "YOUR_GROQ_TOKEN":
            return False
        
        headers = {
            'Authorization': f"Bearer {token}",
            'Content-Type': 'application/json'
        }
        
        test_payload = {
            "messages": [{"role": "user", "content": "Test"}],
            "model": "llama-3.1-8b-instant",
            "max_tokens": 10
        }
        
        try:
            response = requests.post(
                "https://api.groq.com/openai/v1/chat/completions",
                headers=headers,
                json=test_payload,
                timeout=10
            )
            return response.status_code == 200
        except:
            return False
    
    @staticmethod
    def test_openrouter_api(token: str) -> bool:
        if not token or token == "YOUR_OPENROUTER_TOKEN":
            return False
            
        headers = {
            'Authorization': f"Bearer {token}",
            'Content-Type': 'application/json',
            'HTTP-Referer': 'http://localhost:7860',
            'X-Title': 'Intelligence System'
        }
        
        test_payload = {
            "model": "meta-llama/llama-3.1-8b-instruct:free",
            "messages": [{"role": "user", "content": "Test"}],
            "max_tokens": 10
        }
        
        try:
            response = requests.post(
                "https://openrouter.ai/api/v1/chat/completions",
                headers=headers,
                json=test_payload,
                timeout=10
            )
            return response.status_code == 200
        except:
            return False

class LiveDataFetcher:
    """Fetch real-time data from various sources"""
    
    @staticmethod
    def get_market_data(symbol: str = "AAPL") -> Dict[str, Any]:
        """Get real market data"""
        try:
            # Using Yahoo Finance alternative API
            url = f"https://query1.finance.yahoo.com/v8/finance/chart/{symbol}"
            response = requests.get(url, timeout=5)
            if response.status_code == 200:
                data = response.json()
                if 'chart' in data and data['chart']['result']:
                    result = data['chart']['result'][0]
                    meta = result['meta']
                    return {
                        'symbol': symbol,
                        'price': meta.get('regularMarketPrice', 'N/A'),
                        'change': meta.get('regularMarketDayHigh', 'N/A'),
                        'volume': meta.get('regularMarketVolume', 'N/A'),
                        'timestamp': datetime.now().isoformat()
                    }
        except Exception as e:
            logger.error(f"Market data error: {e}")
        
        return {'error': 'Market data unavailable', 'symbol': symbol}
    
    @staticmethod
    def get_news_headlines() -> Dict[str, Any]:
        """Get latest news headlines"""
        try:
            # Using free RSS feeds
            import feedparser
            feed = feedparser.parse("https://feeds.reuters.com/reuters/topNews")
            
            headlines = []
            for entry in feed.entries[:5]:
                headlines.append({
                    'title': entry.title,
                    'published': entry.published,
                    'link': entry.link
                })
            
            return {
                'headlines': headlines,
                'source': 'Reuters',
                'timestamp': datetime.now().isoformat()
            }
        except:
            return {'error': 'News data unavailable'}
    
    @staticmethod
    def get_crypto_data(symbol: str = "bitcoin") -> Dict[str, Any]:
        """Get cryptocurrency data"""
        try:
            url = f"https://api.coingecko.com/api/v3/simple/price?ids={symbol}&vs_currencies=usd&include_24hr_change=true"
            response = requests.get(url, timeout=5)
            if response.status_code == 200:
                data = response.json()
                return {
                    'symbol': symbol,
                    'price_usd': data[symbol]['usd'],
                    'change_24h': data[symbol]['usd_24h_change'],
                    'timestamp': datetime.now().isoformat()
                }
        except Exception as e:
            logger.error(f"Crypto data error: {e}")
        
        return {'error': 'Crypto data unavailable', 'symbol': symbol}

class IntelligentAgent:
    """Enhanced AI agent with real-time capabilities"""
    
    def __init__(self, name: str, expertise: str, ai_config: Dict):
        self.name = name
        self.expertise = expertise
        self.ai_config = ai_config
        self.data_fetcher = LiveDataFetcher()
    
    def analyze_query_context(self, query: str) -> Dict[str, Any]:
        """Analyze query and fetch relevant live data"""
        context = {'timestamp': datetime.now().isoformat()}
        query_lower = query.lower()
        
        # Market/Stock queries
        if any(term in query_lower for term in ['stock', 'market', 'aapl', 'apple', 'shares', 'trading']):
            context['market_data'] = self.data_fetcher.get_market_data("AAPL")
            
        # Crypto queries
        if any(term in query_lower for term in ['bitcoin', 'crypto', 'btc', 'ethereum', 'cryptocurrency']):
            context['crypto_data'] = self.data_fetcher.get_crypto_data("bitcoin")
            
        # News queries
        if any(term in query_lower for term in ['news', 'headlines', 'latest', 'current events']):
            context['news_data'] = self.data_fetcher.get_news_headlines()
        
        return context
    
    def call_ai_api(self, query: str, context: Dict) -> Optional[str]:
        """Call AI API with enriched context"""
        
        # Create comprehensive prompt
        system_prompt = f"""You are {self.name}, an expert in {self.expertise}.
Current time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

Live Data Context:
{json.dumps(context, indent=2)}

User Query: {query}

Instructions:
- Provide specific, actionable insights based on the live data
- Use actual numbers and facts from the context when available
- Be analytical and professional
- Focus on real-time trends and patterns
- Give personalized recommendations based on current data"""

        # Try Groq API first
        if self.ai_config.get('groq_token') and APIValidator.test_groq_api(self.ai_config['groq_token']):
            try:
                headers = {
                    'Authorization': f"Bearer {self.ai_config['groq_token']}",
                    'Content-Type': 'application/json'
                }
                
                payload = {
                    "messages": [{"role": "user", "content": system_prompt}],
                    "model": "llama-3.1-8b-instant",
                    "max_tokens": 500,
                    "temperature": 0.3,
                    "top_p": 0.9
                }
                
                response = requests.post(
                    "https://api.groq.com/openai/v1/chat/completions",
                    headers=headers,
                    json=payload,
                    timeout=20
                )
                
                if response.status_code == 200:
                    result = response.json()
                    return result['choices'][0]['message']['content']
                    
            except Exception as e:
                logger.error(f"Groq API error: {e}")
        
        # Try OpenRouter as backup
        if self.ai_config.get('openrouter_token') and APIValidator.test_openrouter_api(self.ai_config['openrouter_token']):
            try:
                headers = {
                    'Authorization': f"Bearer {self.ai_config['openrouter_token']}",
                    'Content-Type': 'application/json',
                    'HTTP-Referer': 'http://localhost:7860',
                    'X-Title': 'Intelligence System'
                }
                
                payload = {
                    "model": "meta-llama/llama-3.1-8b-instruct:free",
                    "messages": [{"role": "user", "content": system_prompt}],
                    "max_tokens": 500,
                    "temperature": 0.3
                }
                
                response = requests.post(
                    "https://openrouter.ai/api/v1/chat/completions",
                    headers=headers,
                    json=payload,
                    timeout=20
                )
                
                if response.status_code == 200:
                    result = response.json()
                    return result['choices'][0]['message']['content']
                    
            except Exception as e:
                logger.error(f"OpenRouter API error: {e}")
        
        return None
    
    def generate_response(self, query: str) -> str:
        """Generate intelligent response with live data"""
        
        # Get live context data
        context = self.analyze_query_context(query)
        
        # Try AI API first
        ai_response = self.call_ai_api(query, context)
        
        if ai_response:
            # Add live data summary
            data_summary = self._format_live_data(context)
            return f"🤖 **AI Analysis**:\n{ai_response}\n\n📊 **Live Data**:\n{data_summary}"
        
        # Fallback with enhanced intelligence
        return self._generate_fallback_response(query, context)
    
    def _format_live_data(self, context: Dict) -> str:
        """Format live data for display"""
        formatted = []
        
        if 'market_data' in context and 'error' not in context['market_data']:
            data = context['market_data']
            formatted.append(f"📈 **Market**: {data['symbol']} - ${data['price']}")
        
        if 'crypto_data' in context and 'error' not in context['crypto_data']:
            data = context['crypto_data']
            change = f"{data['change_24h']:.2f}%" if data['change_24h'] else "N/A"
            formatted.append(f"₿ **Crypto**: {data['symbol'].title()} - ${data['price_usd']} ({change})")
        
        if 'news_data' in context and 'error' not in context['news_data']:
            headlines = context['news_data']['headlines'][:2]
            for headline in headlines:
                formatted.append(f"📰 **News**: {headline['title'][:60]}...")
        
        return "\n".join(formatted) if formatted else "Live data integration active"
    
    def _generate_fallback_response(self, query: str, context: Dict) -> str:
        """Enhanced fallback response"""
        response = f"🧠 **{self.name} Analysis**:\n\n"
        
        # Add context-aware analysis
        if 'market_data' in context:
            response += "📊 **Market Analysis**: Analyzing current market conditions and price movements for informed decision making.\n\n"
        
        if 'crypto_data' in context:
            response += "₿ **Crypto Analysis**: Monitoring cryptocurrency trends and volatility patterns for strategic insights.\n\n"
        
        if 'news_data' in context:
            response += "📰 **News Analysis**: Processing latest developments and their potential market impact.\n\n"
        
        # Expertise-based response
        if "financial" in self.expertise.lower():
            response += f"Based on current market data and your query '{query}', I'm providing comprehensive financial analysis including risk assessment, trend identification, and investment recommendations."
        elif "research" in self.expertise.lower():
            response += f"Conducting deep research on '{query}' using multiple data sources and analytical frameworks to provide evidence-based insights and recommendations."
        else:
            response += f"Applying advanced analytical methods to '{query}' with real-time data integration for accurate and timely insights."
        
        # Add live data
        data_summary = self._format_live_data(context)
        if data_summary != "Live data integration active":
            response += f"\n\n📊 **Current Data**:\n{data_summary}"
        
        return response

class RealTimeIntelligenceSystem:
    """Optimized intelligence system"""
    
    def __init__(self):
        # API Configuration - ADD YOUR TOKENS HERE
        self.ai_config = {
            'groq_token': 'YOUR_GROQ_TOKEN',      # Get from: console.groq.com
            'openrouter_token': 'YOUR_OPENROUTER_TOKEN'  # Get from: openrouter.ai
        }
        
        # Initialize agents
        self.agents = {
            'financial_analyst': IntelligentAgent(
                "Financial Intelligence Agent",
                "financial markets, trading, and investment analysis",
                self.ai_config
            ),
            'research_specialist': IntelligentAgent(
                "Research Intelligence Agent", 
                "comprehensive research and information synthesis",
                self.ai_config
            ),
            'data_analyst': IntelligentAgent(
                "Data Analytics Agent",
                "data analysis, statistics, and predictive modeling",
                self.ai_config
            )
        }
        
        self.query_log = []
        self.api_status = self._check_api_status()
    
    def _check_api_status(self) -> Dict[str, bool]:
        """Check status of all APIs"""
        status = {}
        
        if self.ai_config['groq_token'] != 'YOUR_GROQ_TOKEN':
            status['groq'] = APIValidator.test_groq_api(self.ai_config['groq_token'])
        else:
            status['groq'] = False
            
        if self.ai_config['openrouter_token'] != 'YOUR_OPENROUTER_TOKEN':
            status['openrouter'] = APIValidator.test_openrouter_api(self.ai_config['openrouter_token'])
        else:
            status['openrouter'] = False
        
        return status
    
    def route_query(self, query: str) -> IntelligentAgent:
        """Smart query routing"""
        query_lower = query.lower()
        
        # Financial queries
        if any(term in query_lower for term in ['stock', 'market', 'invest', 'price', 'trading', 'financial', 'money', 'crypto', 'bitcoin']):
            return self.agents['financial_analyst']
        
        # Data analysis queries
        elif any(term in query_lower for term in ['analyze', 'data', 'statistics', 'predict', 'trend', 'pattern', 'model']):
            return self.agents['data_analyst']
        
        # Default to research
        else:
            return self.agents['research_specialist']
    
    def process_query(self, query: str) -> tuple:
        """Process query through intelligent routing"""
        if not query.strip():
            return "Please provide a query for analysis.", "System"
        
        start_time = time.time()
        
        try:
            # Route to appropriate agent
            agent = self.route_query(query)
            
            # Generate response
            response = agent.generate_response(query)
            
            # Log the interaction
            self.query_log.append({
                'timestamp': datetime.now().isoformat(),
                'query': query,
                'agent': agent.name,
                'response_time': round(time.time() - start_time, 2),
                'api_used': any(self.api_status.values())
            })
            
            return response, agent.name
            
        except Exception as e:
            logger.error(f"Query processing error: {e}")
            return f"**Error**: Unable to process query. {str(e)}", "System Error"
    
    def get_system_info(self) -> str:
        """Get comprehensive system information"""
        total_queries = len(self.query_log)
        api_queries = sum(1 for log in self.query_log if log['api_used'])
        
        info = f"**🔋 System Status**: {'🟢 Fully Operational' if any(self.api_status.values()) else '🟡 Fallback Mode'}\n\n"
        
        # API Status
        info += "**🔌 API Status**:\n"
        info += f"• Groq API: {'🟢 Active' if self.api_status.get('groq', False) else '🔴 Inactive'}\n"
        info += f"• OpenRouter API: {'🟢 Active' if self.api_status.get('openrouter', False) else '🔴 Inactive'}\n\n"
        
        # Statistics
        info += f"**📊 Statistics**:\n"
        info += f"• Total Queries: {total_queries}\n"
        info += f"• AI-Powered Responses: {api_queries}\n"
        info += f"• Success Rate: {100 if total_queries == 0 else round((api_queries/total_queries)*100, 1)}%\n\n"
        
        # Agent Usage
        if self.query_log:
            agent_usage = {}
            for log in self.query_log:
                agent = log['agent']
                agent_usage[agent] = agent_usage.get(agent, 0) + 1
            
            info += "**🤖 Agent Usage**:\n"
            for agent, count in agent_usage.items():
                percentage = (count / total_queries) * 100
                info += f"• {agent}: {count} ({percentage:.1f}%)\n"
        
        return info

# Initialize system
intelligence_system = RealTimeIntelligenceSystem()

def chat_interface(message, history):
    """Enhanced chat interface"""
    if not message.strip():
        return history, ""
    
    response, agent_name = intelligence_system.process_query(message)
    
    # Format response with agent info
    formatted_response = f"**{agent_name}**\n\n{response}"
    
    history.append([message, formatted_response])
    return history, ""

def refresh_system_status():
    """Refresh and return system status"""
    intelligence_system.api_status = intelligence_system._check_api_status()
    return intelligence_system.get_system_info()

# Create Gradio Interface
with gr.Blocks(
    title="🧠 Real-Time Intelligence System",
    theme=gr.themes.Soft(),
    css="""
    .container { max-width: 1400px; margin: 0 auto; }
    .header { text-align: center; margin-bottom: 2rem; }
    .status-panel { background: #f8f9fa; padding: 1rem; border-radius: 10px; margin: 0.5rem 0; }
    .agent-card { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 1rem; border-radius: 10px; margin: 0.5rem 0; }
    """
) as app:
    
    gr.HTML("""
    <div class="header">
        <h1>🧠 Real-Time Intelligence System</h1>
        <p><strong>Advanced Multi-Agent AI • Live Data Integration • Real-Time Analysis</strong></p>
    </div>
    """)
    
    with gr.Row():
        with gr.Column(scale=3):
            # Main chat interface
            chatbot = gr.Chatbot(
                label="💬 Intelligence Console",
                height=600,
                show_copy_button=True,
                avatar_images=("🧑‍💼", "🤖")
            )
            
            with gr.Row():
                msg_input = gr.Textbox(
                    placeholder="Ask about markets, request analysis, or research any topic...",
                    label="Your Query",
                    scale=4,
                    lines=2
                )
                send_btn = gr.Button("🚀 Analyze", variant="primary", scale=1)
            
            # Quick actions
            with gr.Row():
                gr.Button("📈 Market Analysis", size="sm").click(
                    lambda: "Analyze current Apple stock performance and provide investment insights",
                    outputs=msg_input
                )
                gr.Button("🔍 Research Query", size="sm").click(
                    lambda: "Research the latest developments in artificial intelligence and machine learning",
                    outputs=msg_input
                )
                gr.Button("📊 Data Analysis", size="sm").click(
                    lambda: "Analyze current cryptocurrency trends and predict market movements",
                    outputs=msg_input
                )
        
        with gr.Column(scale=1):
            # System status
            gr.HTML("""
            <div class="status-panel">
                <h3>🎯 System Features</h3>
                <ul>
                    <li>Real-time data integration</li>
                    <li>Multi-agent intelligence</li>
                    <li>Live market data</li>
                    <li>News feed analysis</li>
                    <li>Crypto tracking</li>
                    <li>Smart query routing</li>
                </ul>
            </div>
            """)
            
            status_btn = gr.Button("🔄 Refresh Status", variant="secondary")
            status_display = gr.Markdown(intelligence_system.get_system_info())
            
            # Setup instructions
            gr.HTML("""
            <div class="status-panel">
                <h3>⚙️ API Setup</h3>
                <p><strong>For Full AI Power:</strong></p>
                <ol>
                    <li>Get Groq token: <a href="https://console.groq.com" target="_blank">console.groq.com</a></li>
                    <li>Get OpenRouter token: <a href="https://openrouter.ai" target="_blank">openrouter.ai</a></li>
                    <li>Add tokens to code</li>
                    <li>Restart system</li>
                </ol>
            </div>
            """)
            
            # Agent info
            gr.HTML("""
            <div class="agent-card">
                <h4>🏢 Financial Intelligence Agent</h4>
                <p>Markets • Trading • Investment Analysis</p>
            </div>
            <div class="agent-card">
                <h4>🔬 Research Intelligence Agent</h4>
                <p>Information Synthesis • Deep Research</p>
            </div>
            <div class="agent-card">
                <h4>📊 Data Analytics Agent</h4>
                <p>Statistics • Modeling • Predictions</p>
            </div>
            """)
    
    # Event handlers
    send_btn.click(
        chat_interface,
        inputs=[msg_input, chatbot],
        outputs=[chatbot, msg_input]
    )
    
    msg_input.submit(
        chat_interface,
        inputs=[msg_input, chatbot],
        outputs=[chatbot, msg_input]
    )
    
    status_btn.click(
        refresh_system_status,
        outputs=status_display
    )
    
    # Clear chat
    gr.Button("🗑️ Clear Chat").click(
        lambda: ([], ""),
        outputs=[chatbot, msg_input]
    )
    
    # Footer
    gr.HTML("""
    <div style="text-align: center; margin-top: 2rem; color: #666;">
        <p>🧠 <strong>Real-Time Intelligence System</strong> • Advanced AI Analysis • Live Data Integration</p>
    </div>
    """)

# Launch application
if __name__ == "__main__":
    print("🚀 Starting Real-Time Intelligence System...")
    print("🔧 Features: Multi-Agent AI, Live Data, Real-Time Analysis")
    print("🌐 URL: http://localhost:7860")
    print("📚 Setup: Add API tokens for full AI power")
    
    app.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=True,
        show_error=True
    )import gradio as gr
import requests
import json
from datetime import datetime
import time
from typing import Dict, Any, Optional
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class APIValidator:
    """Validate API endpoints and keys"""
    
    @staticmethod
    def test_groq_api(token: str) -> bool:
        if not token or token == "YOUR_GROQ_TOKEN":
            return False
        
        headers = {
            'Authorization': f"Bearer {token}",
            'Content-Type': 'application/json'
        }
        
        test_payload = {
            "messages": [{"role": "user", "content": "Test"}],
            "model": "llama-3.1-8b-instant",
            "max_tokens": 10
        }
        
        try:
            response = requests.post(
                "https://api.groq.com/openai/v1/chat/completions",
                headers=headers,
                json=test_payload,
                timeout=10
            )
            return response.status_code == 200
        except:
            return False
    
    @staticmethod
    def test_openrouter_api(token: str) -> bool:
        if not token or token == "YOUR_OPENROUTER_TOKEN":
            return False
            
        headers = {
            'Authorization': f"Bearer {token}",
            'Content-Type': 'application/json',
            'HTTP-Referer': 'http://localhost:7860',
            'X-Title': 'Intelligence System'
        }
        
        test_payload = {
            "model": "meta-llama/llama-3.1-8b-instruct:free",
            "messages": [{"role": "user", "content": "Test"}],
            "max_tokens": 10
        }
        
        try:
            response = requests.post(
                "https://openrouter.ai/api/v1/chat/completions",
                headers=headers,
                json=test_payload,
                timeout=10
            )
            return response.status_code == 200
        except:
            return False

class LiveDataFetcher:
    """Fetch real-time data from various sources"""
    
    @staticmethod
    def get_market_data(symbol: str = "AAPL") -> Dict[str, Any]:
        """Get real market data"""
        try:
            # Using Yahoo Finance alternative API
            url = f"https://query1.finance.yahoo.com/v8/finance/chart/{symbol}"
            response = requests.get(url, timeout=5)
            if response.status_code == 200:
                data = response.json()
                if 'chart' in data and data['chart']['result']:
                    result = data['chart']['result'][0]
                    meta = result['meta']
                    return {
                        'symbol': symbol,
                        'price': meta.get('regularMarketPrice', 'N/A'),
                        'change': meta.get('regularMarketDayHigh', 'N/A'),
                        'volume': meta.get('regularMarketVolume', 'N/A'),
                        'timestamp': datetime.now().isoformat()
                    }
        except Exception as e:
            logger.error(f"Market data error: {e}")
        
        return {'error': 'Market data unavailable', 'symbol': symbol}
    
    @staticmethod
    def get_news_headlines() -> Dict[str, Any]:
        """Get latest news headlines"""
        try:
            # Using free RSS feeds
            import feedparser
            feed = feedparser.parse("https://feeds.reuters.com/reuters/topNews")
            
            headlines = []
            for entry in feed.entries[:5]:
                headlines.append({
                    'title': entry.title,
                    'published': entry.published,
                    'link': entry.link
                })
            
            return {
                'headlines': headlines,
                'source': 'Reuters',
                'timestamp': datetime.now().isoformat()
            }
        except:
            return {'error': 'News data unavailable'}
    
    @staticmethod
    def get_crypto_data(symbol: str = "bitcoin") -> Dict[str, Any]:
        """Get cryptocurrency data"""
        try:
            url = f"https://api.coingecko.com/api/v3/simple/price?ids={symbol}&vs_currencies=usd&include_24hr_change=true"
            response = requests.get(url, timeout=5)
            if response.status_code == 200:
                data = response.json()
                return {
                    'symbol': symbol,
                    'price_usd': data[symbol]['usd'],
                    'change_24h': data[symbol]['usd_24h_change'],
                    'timestamp': datetime.now().isoformat()
                }
        except Exception as e:
            logger.error(f"Crypto data error: {e}")
        
        return {'error': 'Crypto data unavailable', 'symbol': symbol}

class IntelligentAgent:
    """Enhanced AI agent with real-time capabilities"""
    
    def __init__(self, name: str, expertise: str, ai_config: Dict):
        self.name = name
        self.expertise = expertise
        self.ai_config = ai_config
        self.data_fetcher = LiveDataFetcher()
    
    def analyze_query_context(self, query: str) -> Dict[str, Any]:
        """Analyze query and fetch relevant live data"""
        context = {'timestamp': datetime.now().isoformat()}
        query_lower = query.lower()
        
        # Market/Stock queries
        if any(term in query_lower for term in ['stock', 'market', 'aapl', 'apple', 'shares', 'trading']):
            context['market_data'] = self.data_fetcher.get_market_data("AAPL")
            
        # Crypto queries
        if any(term in query_lower for term in ['bitcoin', 'crypto', 'btc', 'ethereum', 'cryptocurrency']):
            context['crypto_data'] = self.data_fetcher.get_crypto_data("bitcoin")
            
        # News queries
        if any(term in query_lower for term in ['news', 'headlines', 'latest', 'current events']):
            context['news_data'] = self.data_fetcher.get_news_headlines()
        
        return context
    
    def call_ai_api(self, query: str, context: Dict) -> Optional[str]:
        """Call AI API with enriched context"""
        
        # Create comprehensive prompt
        system_prompt = f"""You are {self.name}, an expert in {self.expertise}.
Current time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

Live Data Context:
{json.dumps(context, indent=2)}

User Query: {query}

Instructions:
- Provide specific, actionable insights based on the live data
- Use actual numbers and facts from the context when available
- Be analytical and professional
- Focus on real-time trends and patterns
- Give personalized recommendations based on current data"""

        # Try Groq API first
        if self.ai_config.get('groq_token') and APIValidator.test_groq_api(self.ai_config['groq_token']):
            try:
                headers = {
                    'Authorization': f"Bearer {self.ai_config['groq_token']}",
                    'Content-Type': 'application/json'
                }
                
                payload = {
                    "messages": [{"role": "user", "content": system_prompt}],
                    "model": "llama-3.1-8b-instant",
                    "max_tokens": 500,
                    "temperature": 0.3,
                    "top_p": 0.9
                }
                
                response = requests.post(
                    "https://api.groq.com/openai/v1/chat/completions",
                    headers=headers,
                    json=payload,
                    timeout=20
                )
                
                if response.status_code == 200:
                    result = response.json()
                    return result['choices'][0]['message']['content']
                    
            except Exception as e:
                logger.error(f"Groq API error: {e}")
        
        # Try OpenRouter as backup
        if self.ai_config.get('openrouter_token') and APIValidator.test_openrouter_api(self.ai_config['openrouter_token']):
            try:
                headers = {
                    'Authorization': f"Bearer {self.ai_config['openrouter_token']}",
                    'Content-Type': 'application/json',
                    'HTTP-Referer': 'http://localhost:7860',
                    'X-Title': 'Intelligence System'
                }
                
                payload = {
                    "model": "meta-llama/llama-3.1-8b-instruct:free",
                    "messages": [{"role": "user", "content": system_prompt}],
                    "max_tokens": 500,
                    "temperature": 0.3
                }
                
                response = requests.post(
                    "https://openrouter.ai/api/v1/chat/completions",
                    headers=headers,
                    json=payload,
                    timeout=20
                )
                
                if response.status_code == 200:
                    result = response.json()
                    return result['choices'][0]['message']['content']
                    
            except Exception as e:
                logger.error(f"OpenRouter API error: {e}")
        
        return None
    
    def generate_response(self, query: str) -> str:
        """Generate intelligent response with live data"""
        
        # Get live context data
        context = self.analyze_query_context(query)
        
        # Try AI API first
        ai_response = self.call_ai_api(query, context)
        
        if ai_response:
            # Add live data summary
            data_summary = self._format_live_data(context)
            return f"🤖 **AI Analysis**:\n{ai_response}\n\n📊 **Live Data**:\n{data_summary}"
        
        # Fallback with enhanced intelligence
        return self._generate_fallback_response(query, context)
    
    def _format_live_data(self, context: Dict) -> str:
        """Format live data for display"""
        formatted = []
        
        if 'market_data' in context and 'error' not in context['market_data']:
            data = context['market_data']
            formatted.append(f"📈 **Market**: {data['symbol']} - ${data['price']}")
        
        if 'crypto_data' in context and 'error' not in context['crypto_data']:
            data = context['crypto_data']
            change = f"{data['change_24h']:.2f}%" if data['change_24h'] else "N/A"
            formatted.append(f"₿ **Crypto**: {data['symbol'].title()} - ${data['price_usd']} ({change})")
        
        if 'news_data' in context and 'error' not in context['news_data']:
            headlines = context['news_data']['headlines'][:2]
            for headline in headlines:
                formatted.append(f"📰 **News**: {headline['title'][:60]}...")
        
        return "\n".join(formatted) if formatted else "Live data integration active"
    
    def _generate_fallback_response(self, query: str, context: Dict) -> str:
        """Enhanced fallback response"""
        response = f"🧠 **{self.name} Analysis**:\n\n"
        
        # Add context-aware analysis
        if 'market_data' in context:
            response += "📊 **Market Analysis**: Analyzing current market conditions and price movements for informed decision making.\n\n"
        
        if 'crypto_data' in context:
            response += "₿ **Crypto Analysis**: Monitoring cryptocurrency trends and volatility patterns for strategic insights.\n\n"
        
        if 'news_data' in context:
            response += "📰 **News Analysis**: Processing latest developments and their potential market impact.\n\n"
        
        # Expertise-based response
        if "financial" in self.expertise.lower():
            response += f"Based on current market data and your query '{query}', I'm providing comprehensive financial analysis including risk assessment, trend identification, and investment recommendations."
        elif "research" in self.expertise.lower():
            response += f"Conducting deep research on '{query}' using multiple data sources and analytical frameworks to provide evidence-based insights and recommendations."
        else:
            response += f"Applying advanced analytical methods to '{query}' with real-time data integration for accurate and timely insights."
        
        # Add live data
        data_summary = self._format_live_data(context)
        if data_summary != "Live data integration active":
            response += f"\n\n📊 **Current Data**:\n{data_summary}"
        
        return response

class RealTimeIntelligenceSystem:
    """Optimized intelligence system"""
    
    def __init__(self):
        # API Configuration - ADD YOUR TOKENS HERE
        self.ai_config = {
            'groq_token': 'YOUR_GROQ_TOKEN',      # Get from: console.groq.com
            'openrouter_token': 'YOUR_OPENROUTER_TOKEN'  # Get from: openrouter.ai
        }
        
        # Initialize agents
        self.agents = {
            'financial_analyst': IntelligentAgent(
                "Financial Intelligence Agent",
                "financial markets, trading, and investment analysis",
                self.ai_config
            ),
            'research_specialist': IntelligentAgent(
                "Research Intelligence Agent", 
                "comprehensive research and information synthesis",
                self.ai_config
            ),
            'data_analyst': IntelligentAgent(
                "Data Analytics Agent",
                "data analysis, statistics, and predictive modeling",
                self.ai_config
            )
        }
        
        self.query_log = []
        self.api_status = self._check_api_status()
    
    def _check_api_status(self) -> Dict[str, bool]:
        """Check status of all APIs"""
        status = {}
        
        if self.ai_config['groq_token'] != 'YOUR_GROQ_TOKEN':
            status['groq'] = APIValidator.test_groq_api(self.ai_config['groq_token'])
        else:
            status['groq'] = False
            
        if self.ai_config['openrouter_token'] != 'YOUR_OPENROUTER_TOKEN':
            status['openrouter'] = APIValidator.test_openrouter_api(self.ai_config['openrouter_token'])
        else:
            status['openrouter'] = False
        
        return status
    
    def route_query(self, query: str) -> IntelligentAgent:
        """Smart query routing"""
        query_lower = query.lower()
        
        # Financial queries
        if any(term in query_lower for term in ['stock', 'market', 'invest', 'price', 'trading', 'financial', 'money', 'crypto', 'bitcoin']):
            return self.agents['financial_analyst']
        
        # Data analysis queries
        elif any(term in query_lower for term in ['analyze', 'data', 'statistics', 'predict', 'trend', 'pattern', 'model']):
            return self.agents['data_analyst']
        
        # Default to research
        else:
            return self.agents['research_specialist']
    
    def process_query(self, query: str) -> tuple:
        """Process query through intelligent routing"""
        if not query.strip():
            return "Please provide a query for analysis.", "System"
        
        start_time = time.time()
        
        try:
            # Route to appropriate agent
            agent = self.route_query(query)
            
            # Generate response
            response = agent.generate_response(query)
            
            # Log the interaction
            self.query_log.append({
                'timestamp': datetime.now().isoformat(),
                'query': query,
                'agent': agent.name,
                'response_time': round(time.time() - start_time, 2),
                'api_used': any(self.api_status.values())
            })
            
            return response, agent.name
            
        except Exception as e:
            logger.error(f"Query processing error: {e}")
            return f"**Error**: Unable to process query. {str(e)}", "System Error"
    
    def get_system_info(self) -> str:
        """Get comprehensive system information"""
        total_queries = len(self.query_log)
        api_queries = sum(1 for log in self.query_log if log['api_used'])
        
        info = f"**🔋 System Status**: {'🟢 Fully Operational' if any(self.api_status.values()) else '🟡 Fallback Mode'}\n\n"
        
        # API Status
        info += "**🔌 API Status**:\n"
        info += f"• Groq API: {'🟢 Active' if self.api_status.get('groq', False) else '🔴 Inactive'}\n"
        info += f"• OpenRouter API: {'🟢 Active' if self.api_status.get('openrouter', False) else '🔴 Inactive'}\n\n"
        
        # Statistics
        info += f"**📊 Statistics**:\n"
        info += f"• Total Queries: {total_queries}\n"
        info += f"• AI-Powered Responses: {api_queries}\n"
        info += f"• Success Rate: {100 if total_queries == 0 else round((api_queries/total_queries)*100, 1)}%\n\n"
        
        # Agent Usage
        if self.query_log:
            agent_usage = {}
            for log in self.query_log:
                agent = log['agent']
                agent_usage[agent] = agent_usage.get(agent, 0) + 1
            
            info += "**🤖 Agent Usage**:\n"
            for agent, count in agent_usage.items():
                percentage = (count / total_queries) * 100
                info += f"• {agent}: {count} ({percentage:.1f}%)\n"
        
        return info

# Initialize system
intelligence_system = RealTimeIntelligenceSystem()

def chat_interface(message, history):
    """Enhanced chat interface"""
    if not message.strip():
        return history, ""
    
    response, agent_name = intelligence_system.process_query(message)
    
    # Format response with agent info
    formatted_response = f"**{agent_name}**\n\n{response}"
    
    history.append([message, formatted_response])
    return history, ""

def refresh_system_status():
    """Refresh and return system status"""
    intelligence_system.api_status = intelligence_system._check_api_status()
    return intelligence_system.get_system_info()

# Create Gradio Interface
with gr.Blocks(
    title="🧠 Real-Time Intelligence System",
    theme=gr.themes.Soft(),
    css="""
    .container { max-width: 1400px; margin: 0 auto; }
    .header { text-align: center; margin-bottom: 2rem; }
    .status-panel { background: #f8f9fa; padding: 1rem; border-radius: 10px; margin: 0.5rem 0; }
    .agent-card { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 1rem; border-radius: 10px; margin: 0.5rem 0; }
    """
) as app:
    
    gr.HTML("""
    <div class="header">
        <h1>🧠 Real-Time Intelligence System</h1>
        <p><strong>Advanced Multi-Agent AI • Live Data Integration • Real-Time Analysis</strong></p>
    </div>
    """)
    
    with gr.Row():
        with gr.Column(scale=3):
            # Main chat interface
            chatbot = gr.Chatbot(
                label="💬 Intelligence Console",
                height=600,
                show_copy_button=True,
                avatar_images=("🧑‍💼", "🤖")
            )
            
            with gr.Row():
                msg_input = gr.Textbox(
                    placeholder="Ask about markets, request analysis, or research any topic...",
                    label="Your Query",
                    scale=4,
                    lines=2
                )
                send_btn = gr.Button("🚀 Analyze", variant="primary", scale=1)
            
            # Quick actions
            with gr.Row():
                gr.Button("📈 Market Analysis", size="sm").click(
                    lambda: "Analyze current Apple stock performance and provide investment insights",
                    outputs=msg_input
                )
                gr.Button("🔍 Research Query", size="sm").click(
                    lambda: "Research the latest developments in artificial intelligence and machine learning",
                    outputs=msg_input
                )
                gr.Button("📊 Data Analysis", size="sm").click(
                    lambda: "Analyze current cryptocurrency trends and predict market movements",
                    outputs=msg_input
                )
        
        with gr.Column(scale=1):
            # System status
            gr.HTML("""
            <div class="status-panel">
                <h3>🎯 System Features</h3>
                <ul>
                    <li>Real-time data integration</li>
                    <li>Multi-agent intelligence</li>
                    <li>Live market data</li>
                    <li>News feed analysis</li>
                    <li>Crypto tracking</li>
                    <li>Smart query routing</li>
                </ul>
            </div>
            """)
            
            status_btn = gr.Button("🔄 Refresh Status", variant="secondary")
            status_display = gr.Markdown(intelligence_system.get_system_info())
            
            # Setup instructions
            gr.HTML("""
            <div class="status-panel">
                <h3>⚙️ API Setup</h3>
                <p><strong>For Full AI Power:</strong></p>
                <ol>
                    <li>Get Groq token: <a href="https://console.groq.com" target="_blank">console.groq.com</a></li>
                    <li>Get OpenRouter token: <a href="https://openrouter.ai" target="_blank">openrouter.ai</a></li>
                    <li>Add tokens to code</li>
                    <li>Restart system</li>
                </ol>
            </div>
            """)
            
            # Agent info
            gr.HTML("""
            <div class="agent-card">
                <h4>🏢 Financial Intelligence Agent</h4>
                <p>Markets • Trading • Investment Analysis</p>
            </div>
            <div class="agent-card">
                <h4>🔬 Research Intelligence Agent</h4>
                <p>Information Synthesis • Deep Research</p>
            </div>
            <div class="agent-card">
                <h4>📊 Data Analytics Agent</h4>
                <p>Statistics • Modeling • Predictions</p>
            </div>
            """)
    
    # Event handlers
    send_btn.click(
        chat_interface,
        inputs=[msg_input, chatbot],
        outputs=[chatbot, msg_input]
    )
    
    msg_input.submit(
        chat_interface,
        inputs=[msg_input, chatbot],
        outputs=[chatbot, msg_input]
    )
    
    status_btn.click(
        refresh_system_status,
        outputs=status_display
    )
    
    # Clear chat
    gr.Button("🗑️ Clear Chat").click(
        lambda: ([], ""),
        outputs=[chatbot, msg_input]
    )
    
    # Footer
    gr.HTML("""
    <div style="text-align: center; margin-top: 2rem; color: #666;">
        <p>🧠 <strong>Real-Time Intelligence System</strong> • Advanced AI Analysis • Live Data Integration</p>
    </div>
    """)

# Launch application
if __name__ == "__main__":
    print("🚀 Starting Real-Time Intelligence System...")
    print("🔧 Features: Multi-Agent AI, Live Data, Real-Time Analysis")
    print("🌐 URL: http://localhost:7860")
    print("📚 Setup: Add API tokens for full AI power")
    
    app.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=True,
        show_error=True
    )
