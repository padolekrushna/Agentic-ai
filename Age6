import gradio as gr
import requests
import json
import time
import random

class SimpleAgent:
    def __init__(self, name, role, hf_token=None):
        self.name = name
        self.role = role
        self.hf_token = hf_token
        self.hf_models = [
            "microsoft/DialoGPT-medium",
            "facebook/blenderbot-400M-distill",
            "microsoft/DialoGPT-small"
        ]
    
    def get_hf_response(self, query):
        """Get response from Hugging Face API"""
        if not self.hf_token or self.hf_token == "YOUR_HF_TOKEN":
            return None
            
        headers = {
            "Authorization": f"Bearer {self.hf_token}",
            "Content-Type": "application/json"
        }
        
        # Try different models if one fails
        for model in self.hf_models:
            try:
                url = f"https://api-inference.huggingface.co/models/{model}"
                payload = {"inputs": f"As a {self.role}: {query}"}
                
                response = requests.post(url, headers=headers, json=payload, timeout=15)
                
                if response.status_code == 200:
                    result = response.json()
                    if isinstance(result, list) and result:
                        text = result[0].get('generated_text', '')
                        # Clean up the response
                        if query in text:
                            text = text.replace(query, '').strip()
                        return text[:500] if text else None
                elif response.status_code == 503:
                    # Model loading, try next one
                    continue
                    
            except Exception:
                continue
        
        return None
    
    def get_ollama_response(self, query):
        """Try local Ollama API (if available)"""
        try:
            url = "http://localhost:11434/api/generate"
            payload = {
                "model": "llama2",
                "prompt": f"As a {self.role}, answer briefly: {query}",
                "stream": False
            }
            response = requests.post(url, json=payload, timeout=10)
            if response.status_code == 200:
                return response.json().get('response', '')[:300]
        except:
            pass
        return None
    
    def get_fallback_response(self, query):
        """Smart fallback responses"""
        query_lower = query.lower()
        
        if "tech" in self.role.lower():
            if any(word in query_lower for word in ['error', 'bug', '404', 'crash', 'problem']):
                responses = [
                    "I can help with that technical issue. Try clearing your cache and cookies first.",
                    "For this error, please check your internet connection and try refreshing the page.",
                    "This looks like a common issue. Have you tried restarting the application?",
                    "Let me help troubleshoot this. Can you tell me when exactly this error occurs?"
                ]
            elif any(word in query_lower for word in ['api', 'code', 'integration']):
                responses = [
                    "For API issues, first verify your API key is valid and has proper permissions.",
                    "Check if you're hitting rate limits. Most free APIs have daily/hourly limits.",
                    "Make sure your request format matches the API documentation exactly.",
                    "Try testing with a simple API call first to isolate the issue."
                ]
            else:
                responses = [
                    f"As your technical support specialist, I can help with: {query}. What specific details can you provide?",
                    "I handle technical issues, bugs, and integrations. Could you describe the problem in more detail?",
                    "Let me assist with your technical question. What steps have you already tried?"
                ]
        
        elif "billing" in self.role.lower():
            if any(word in query_lower for word in ['refund', 'money', 'charge', 'payment']):
                responses = [
                    "I can help with billing issues. Refunds typically take 3-5 business days to process.",
                    "For payment problems, please provide your transaction ID so I can look into it.",
                    "Billing disputes can be resolved quickly. Let me check your account details.",
                    "I'll help with your payment concern. What specific billing issue are you experiencing?"
                ]
            elif any(word in query_lower for word in ['price', 'cost', 'plan', 'subscription']):
                responses = [
                    "Our pricing is transparent: Free tier with limits, Pro at $10/month, Enterprise custom.",
                    "I can explain our different plans and help you choose the right one for your needs.",
                    "Subscription changes take effect immediately. Would you like to upgrade or downgrade?",
                    "Let me break down the costs and features of each plan for you."
                ]
            else:
                responses = [
                    f"As your billing specialist, I handle all payment-related questions about: {query}",
                    "I can help with subscriptions, refunds, and pricing. What do you need assistance with?",
                    "For any billing concerns, I'm here to help resolve them quickly."
                ]
        
        else:  # General support
            responses = [
                f"I'm here to help with your question about: {query}. How can I assist you further?",
                "As your general support agent, I can guide you to the right resources or specialist.",
                "I'd be happy to help! Could you provide a bit more context about what you need?",
                f"Let me help you with '{query}'. What specific information are you looking for?"
            ]
        
        return random.choice(responses)
    
    def respond(self, query):
        """Main response method with multiple fallbacks"""
        # Try Hugging Face first
        response = self.get_hf_response(query)
        if response and len(response.strip()) > 10:
            return f"ü§ñ {response}"
        
        # Try Ollama (local) as backup
        response = self.get_ollama_response(query)
        if response and len(response.strip()) > 10:
            return f"ü¶ô {response}"
        
        # Use smart fallback
        return f"üí° {self.get_fallback_response(query)}"

class MultiAgentSystem:
    def __init__(self, hf_token=None):
        self.agents = {
            'tech': SimpleAgent("Tech Support", "technical support specialist", hf_token),
            'billing': SimpleAgent("Billing Agent", "billing and payment specialist", hf_token),
            'general': SimpleAgent("General Support", "helpful customer service representative", hf_token)
        }
        self.history = []
    
    def route_query(self, query):
        """Simple keyword-based routing"""
        query_lower = query.lower()
        
        if any(word in query_lower for word in ['technical', 'bug', 'error', 'code', 'api', '404', 'crash']):
            return 'tech'
        elif any(word in query_lower for word in ['billing', 'payment', 'refund', 'price', 'cost', 'subscription']):
            return 'billing'
        else:
            return 'general'
    
    def process(self, query):
        """Process query through appropriate agent"""
        if not query.strip():
            return "Please enter a question."
        
        agent_type = self.route_query(query)
        agent = self.agents[agent_type]
        
        response = agent.respond(query)
        
        # Add to history
        self.history.append({
            'query': query,
            'agent': agent.name,
            'response': response
        })
        
        return f"**{agent.name}**: {response}"

# Initialize system
def create_system():
    # Put your Hugging Face token here
    HF_TOKEN = "YOUR_HF_TOKEN"  # Replace with your actual token
    return MultiAgentSystem(HF_TOKEN)

system = create_system()

def chat_function(message, history):
    """Main chat function"""
    if not message.strip():
        return history, ""
    
    try:
        response = system.process(message)
        history.append([message, response])
        return history, ""
    except Exception as e:
        error_msg = f"System Error: {str(e)}"
        history.append([message, error_msg])
        return history, ""

def get_stats():
    """Get system statistics"""
    if not system.history:
        return "No conversations yet."
    
    stats = f"Total Queries: {len(system.history)}\n"
    
    # Count by agent
    agent_counts = {}
    for conv in system.history:
        agent = conv['agent']
        agent_counts[agent] = agent_counts.get(agent, 0) + 1
    
    stats += "\nAgent Usage:\n"
    for agent, count in agent_counts.items():
        stats += f"‚Ä¢ {agent}: {count} queries\n"
    
    return stats

# Create Gradio interface
with gr.Blocks(title="Multi-Agent AI System", theme="soft") as app:
    gr.Markdown("# ü§ñ Multi-Agent AI System")
    gr.Markdown("**Smart routing to specialized agents: Technical Support, Billing, and General Support**")
    
    with gr.Row():
        with gr.Column(scale=3):
            chatbot = gr.Chatbot(
                label="Chat with AI Agents",
                height=500,
                show_copy_button=True
            )
            
            with gr.Row():
                msg = gr.Textbox(
                    placeholder="Ask your question here...",
                    label="Your Message",
                    scale=4
                )
                send_btn = gr.Button("Send", variant="primary", scale=1)
            
            with gr.Row():
                clear_btn = gr.Button("Clear Chat", variant="secondary")
                
        with gr.Column(scale=1):
            gr.Markdown("### üìä System Stats")
            stats_btn = gr.Button("Refresh Stats")
            stats_display = gr.Textbox(
                label="Statistics",
                lines=8,
                interactive=False
            )
            
            gr.Markdown("### üîß Setup Status")
            setup_info = gr.Markdown("""
            **Status**: Ready to use!
            
            **Current Mode**: Fallback responses active
            
            **To enable full AI**:
            1. Add your HF token to `HF_TOKEN` variable
            2. Restart the app
            
            **Test queries**:
            - "I have a 404 error" ‚Üí Tech Agent
            - "I need a refund" ‚Üí Billing Agent  
            - "How do I get started?" ‚Üí General Agent
            """)

    # Event handlers
    send_btn.click(
        chat_function,
        inputs=[msg, chatbot],
        outputs=[chatbot, msg]
    )
    
    msg.submit(
        chat_function,
        inputs=[msg, chatbot],
        outputs=[chatbot, msg]
    )
    
    clear_btn.click(
        lambda: ([], ""),
        outputs=[chatbot, msg]
    )
    
    stats_btn.click(
        get_stats,
        outputs=stats_display
    )

# Launch
if __name__ == "__main__":
    print("üöÄ Starting Multi-Agent AI System...")
    print("üìù Remember to add your Hugging Face token!")
    app.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=True,
        show_error=True
    )
