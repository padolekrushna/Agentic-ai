# ‚úÖ Install Compatible Versions
!pip install -q langchain==0.1.14 langchain-experimental==0.0.23 duckduckgo-search wikipedia gradio transformers accelerate huggingface_hub

# ‚úÖ Imports
import os
import gradio as gr
from langchain.agents import Tool, initialize_agent, AgentType
from langchain.tools import DuckDuckGoSearchRun, WikipediaQueryRun
from langchain_experimental.tools.python.tool import PythonREPLTool  # ‚úÖ CORRECT for this version
from langchain.llms import HuggingFaceHub

# ‚úÖ Hugging Face token
os.environ["HUGGINGFACEHUB_API_TOKEN"] = "your_huggingface_token_here"

# ‚úÖ Load FLAN-T5
llm = HuggingFaceHub(
    repo_id="google/flan-t5-small",
    model_kwargs={"temperature": 0.3, "max_length": 256}
)

# ‚úÖ Setup Tools
search_tool = DuckDuckGoSearchRun()
wiki_tool = WikipediaQueryRun()
math_tool = PythonREPLTool()

tools = [
    Tool(name="DuckDuckGo Search", func=search_tool.run, description="Search web"),
    Tool(name="Wikipedia", func=wiki_tool.run, description="Factual info from Wikipedia"),
    Tool(name="PythonREPL", func=math_tool.run, description="Math or code execution")
]

# ‚úÖ Create Agent
agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=False)

# ‚úÖ Gradio Interface
def run_agent(query):
    try:
        result = agent.run(query)
        with open("saved_answers.txt", "a", encoding="utf-8") as f:
            f.write(f"\nUser Query: {query}\nAgent Answer: {result}\n{'-'*40}")
        return result
    except Exception as e:
        return f"‚ùå Error: {str(e)}"

gr.Interface(
    fn=run_agent,
    inputs=gr.Textbox(label="Your Question"),
    outputs=gr.Textbox(label="Agent's Answer"),
    title="ü§ñ RaMARA ‚Äì Fast Multi-Agent AI",
    description="Powered by LangChain, FLAN-T5, DuckDuckGo, and Wikipedia"
).launch()
    
